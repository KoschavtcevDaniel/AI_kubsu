{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d25b56f6-c85a-416d-89a8-7031c1a3bc81","cell_type":"markdown","source":"### ОТБОР АВТОМАТИЧЕСКИ СГЕНЕРИРОВАННЫХ ПРИЗНАКОВ","metadata":{}},{"id":"82502b36-f74f-453c-81a3-48cb938f3676","cell_type":"markdown","source":"Предположим, вам удалось автоматически сгенерировать большое количество признаков, описывающих набор данных большого временного ряда. Скорее всего, вам не удастся оценить их все при первом же просмотре данных, поэтому всегда не лишне дополнить функцию автоматической генерации признаков возможностью их автоматического отбора. К одним из лучших инструментов отбора признаков относится алгоритм FRESH, который реализован в описанном ранее пакете tsfresh. Этот алгоритм выбирает релевантные признаки на основе масштабируемых критериев проверки гипотез. Необходимость в разработке алгоритма FRESH была вызвана постоянно увеличивающимся объемом данных временных рядов, зачастую подлежащих распределенному хранению с целью последующего распараллеливания вычислений.\nАлгоритм оценивает значимость каждого входного признака по отношению к целевой переменной методом вычисления p-значения для каждого из них. После этого p-значения каждого признака оцениваются в совокупности с помощью процедуры Бенджамини-Екутиели, учитывающей такие входные параметры, как уровень допустимых погрешностей, и указывающей, какие из признаков следует сохранить для дальнейшего использования. Процедура Бенджамини-Екутиели — это метод ограничения количества ложных срабатываний, обнаруженных во время проверки гипотез, используемый для получения p-значений на начальном этапе алгоритма FRESH.\nСамостоятельная реализация таких процедур — это довольно сложная задача, но воспользовавшись пакетом tsfresh, ее можно решить всего в несколько строк кода. В следующем примере использован шаблон кода, приведенный в документации к модулю. Вначале нужно загрузить данные временных рядов, относящиеся к сбоям в работе робота.\n","metadata":{}},{"id":"ad77c1ec-ff5f-48a1-aab9-4c749f587b70","cell_type":"code","source":"pip install numpy==1.23.5","metadata":{"execution":{"iopub.status.busy":"2024-12-08T11:10:17.300509Z","iopub.execute_input":"2024-12-08T11:10:17.301046Z","iopub.status.idle":"2024-12-08T11:10:34.996458Z","shell.execute_reply.started":"2024-12-08T11:10:17.300991Z","shell.execute_reply":"2024-12-08T11:10:34.995082Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting numpy==1.23.5\n  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\nDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nalbucore 0.0.17 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\nalbumentations 1.4.17 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\nbayesian-optimization 1.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\nblis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.23.5 which is incompatible.\nchex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\njax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\njaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nxarray 2024.9.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\nxarray 2024.9.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.23.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"id":"0be23f3c-1535-448b-99c9-11ba7386b855","cell_type":"code","source":"import tsfresh","metadata":{"execution":{"iopub.status.busy":"2024-12-08T11:10:34.999365Z","iopub.execute_input":"2024-12-08T11:10:34.999788Z","iopub.status.idle":"2024-12-08T11:10:38.703594Z","shell.execute_reply.started":"2024-12-08T11:10:34.999748Z","shell.execute_reply":"2024-12-08T11:10:38.702407Z"},"trusted":true},"outputs":[],"execution_count":2},{"id":"d193a774-c449-4bde-9139-d2ba80678992","cell_type":"code","source":"from tsfresh.examples.robot_execution_failures import download_robot_execution_failures, load_robot_execution_failures\ndownload_robot_execution_failures()\ntimeseries, y = load_robot_execution_failures()","metadata":{"execution":{"iopub.status.busy":"2024-12-08T11:10:38.704907Z","iopub.execute_input":"2024-12-08T11:10:38.705468Z","iopub.status.idle":"2024-12-08T11:10:39.089809Z","shell.execute_reply.started":"2024-12-08T11:10:38.705432Z","shell.execute_reply":"2024-12-08T11:10:39.087970Z"},"trusted":true},"outputs":[],"execution_count":3},{"id":"604dedd3-bc1d-4083-a9cd-985371b10c36","cell_type":"markdown","source":"Признаки извлекаются без дополнительного указания, поэтому пакет автоматически вычисляет их все. В этом смысле он поступает вразрез с предостережениями, приведенными ранее, оставаясь достаточно беспечным относительно экономии вычислительных ресурсов. В тестовом наборе данных не слишком много точек данных, но вы, вероятнее всего, откажетесь от полной их обработки, предварительно не сократив до разумного количества.","metadata":{}},{"id":"b4e0f00f-9e54-40df-adf1-53b6448541c1","cell_type":"code","source":"from tsfresh import extract_features\nextracted_features = extract_features(timeseries, column_id=\"id\", column_sort=\"time\")","metadata":{"execution":{"iopub.status.busy":"2024-12-08T11:10:39.091520Z","iopub.execute_input":"2024-12-08T11:10:39.091977Z","iopub.status.idle":"2024-12-08T11:11:07.757276Z","shell.execute_reply.started":"2024-12-08T11:10:39.091886Z","shell.execute_reply":"2024-12-08T11:11:07.755952Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Feature Extraction: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it]\n","output_type":"stream"}],"execution_count":4},{"id":"1299c7d5-58ed-4072-b477-3d72454723b1","cell_type":"markdown","source":"Хотя пакет tsfresh позволяет указывать вычисляемые признаки, в настоящем примере мы будем рассматривать все возможные варианты. Заметьте, что всегда можно указать параметры для тех признаков, которые должны приниматься в расчет при вычислении. Все возможности детально описаны и проиллюстрированы в документации.\nПроведя полное извлечение для данных — в нашем случае включенных в пакет tsfresh — можно получить огромное количество признаков .\n","metadata":{}},{"id":"7fe5dcc1-e972-44db-8158-5089698a447e","cell_type":"code","source":"# Пример длинного списка признаков\ncolumns = ['F_x_abs_energy', 'F_x_absolute_sum_of_changes', \n           'F_x_agg_autocorrelation_f_agg_mean', \n           'F_x_agg_autocorrelation_f_agg_median', \n           'F_x_agg_autocorrelation_f_agg_var', \n           'F_x_agg_linear_trend_f_agg_max_chunk_len_10_attr_intercept', \n           'F_x_agg_linear_trend_f_agg_max_chunk_len_10_attr_rvalue', \n           'F_x_agg_linear_trend_f_agg_max_chunk_len_10_attr_slope', \n           'F_x_agg_linear_trend_f_agg_max_chunk_len_10_attr_stderr', \n           'F_x_agg_linear_trend_f_agg_max_chunk_len_50_attr_intercept',\n           # ... [другие признаки]\n           'T_z__variance_larger_than_standard_deviation']\n\n# Получение списка столбцов из extracted_features\ncolumns = extracted_features.columns.tolist()\n\n# Замена списка признаков\nextracted_features.columns = columns","metadata":{"execution":{"iopub.status.busy":"2024-12-08T11:11:07.760236Z","iopub.execute_input":"2024-12-08T11:11:07.760693Z","iopub.status.idle":"2024-12-08T11:11:07.769549Z","shell.execute_reply.started":"2024-12-08T11:11:07.760628Z","shell.execute_reply":"2024-12-08T11:11:07.768085Z"},"trusted":true},"outputs":[],"execution_count":5},{"id":"51922d59-5401-488f-aa82-deda4f8d5770","cell_type":"code","source":"print(extracted_features)","metadata":{"execution":{"iopub.status.busy":"2024-12-08T11:11:07.771313Z","iopub.execute_input":"2024-12-08T11:11:07.771937Z","iopub.status.idle":"2024-12-08T11:11:08.008006Z","shell.execute_reply.started":"2024-12-08T11:11:07.771874Z","shell.execute_reply":"2024-12-08T11:11:08.006847Z"},"trusted":true},"outputs":[{"name":"stdout","text":"    F_x__variance_larger_than_standard_deviation  F_x__has_duplicate_max  \\\n1                                            0.0                     0.0   \n2                                            0.0                     1.0   \n3                                            0.0                     0.0   \n4                                            0.0                     1.0   \n5                                            0.0                     0.0   \n..                                           ...                     ...   \n84                                           1.0                     1.0   \n85                                           1.0                     0.0   \n86                                           1.0                     0.0   \n87                                           1.0                     1.0   \n88                                           1.0                     0.0   \n\n    F_x__has_duplicate_min  F_x__has_duplicate  F_x__sum_values  \\\n1                      1.0                 1.0            -14.0   \n2                      1.0                 1.0            -13.0   \n3                      1.0                 1.0            -10.0   \n4                      1.0                 1.0             -6.0   \n5                      0.0                 1.0             -9.0   \n..                     ...                 ...              ...   \n84                     0.0                 1.0          -1073.0   \n85                     1.0                 1.0            143.0   \n86                     0.0                 0.0            961.0   \n87                     0.0                 1.0           4509.0   \n88                     1.0                 1.0           -143.0   \n\n    F_x__abs_energy  F_x__mean_abs_change  F_x__mean_change  \\\n1              14.0              0.142857          0.000000   \n2              25.0              1.000000          0.000000   \n3              12.0              0.714286          0.000000   \n4              16.0              1.214286         -0.071429   \n5              17.0              0.928571         -0.071429   \n..              ...                   ...               ...   \n84          96833.0              7.142857         -5.428571   \n85           1683.0              1.357143          1.071429   \n86          83497.0              9.071429          9.071429   \n87        1405437.0             12.928571         12.214286   \n88           1427.0              0.785714         -0.500000   \n\n    F_x__mean_second_derivative_central  F_x__median  ...  \\\n1                             -0.038462         -1.0  ...   \n2                             -0.038462         -1.0  ...   \n3                             -0.038462         -1.0  ...   \n4                             -0.038462          0.0  ...   \n5                              0.038462         -1.0  ...   \n..                                  ...          ...  ...   \n84                            -0.038462        -98.0  ...   \n85                             0.076923          8.0  ...   \n86                             0.807692         52.0  ...   \n87                            -1.038462        338.0  ...   \n88                             0.038462         -9.0  ...   \n\n    T_z__fourier_entropy__bins_5  T_z__fourier_entropy__bins_10  \\\n1                            NaN                            NaN   \n2                       1.073543                       1.494175   \n3                       1.386294                       1.732868   \n4                       1.073543                       1.494175   \n5                       0.900256                       1.320888   \n..                           ...                            ...   \n84                      0.735622                       0.735622   \n85                      0.735622                       0.735622   \n86                      0.735622                       1.073543   \n87                      0.735622                       0.735622   \n88                      1.255482                       1.494175   \n\n    T_z__fourier_entropy__bins_100  \\\n1                              NaN   \n2                         2.079442   \n3                         2.079442   \n4                         2.079442   \n5                         2.079442   \n..                             ...   \n84                        1.386294   \n85                        1.667462   \n86                        1.732868   \n87                        1.386294   \n88                        2.079442   \n\n    T_z__permutation_entropy__dimension_3__tau_1  \\\n1                                      -0.000000   \n2                                       0.937156   \n3                                       1.265857   \n4                                       1.156988   \n5                                       1.156988   \n..                                           ...   \n84                                      1.585771   \n85                                      1.332245   \n86                                      0.687092   \n87                                      0.535961   \n88                                      0.830518   \n\n    T_z__permutation_entropy__dimension_4__tau_1  \\\n1                                      -0.000000   \n2                                       1.234268   \n3                                       1.704551   \n4                                       1.907284   \n5                                       1.863680   \n..                                           ...   \n84                                      2.253858   \n85                                      1.589027   \n86                                      0.983088   \n87                                      0.836988   \n88                                      1.242453   \n\n    T_z__permutation_entropy__dimension_5__tau_1  \\\n1                                      -0.000000   \n2                                       1.540306   \n3                                       2.019815   \n4                                       2.397895   \n5                                       2.271869   \n..                                           ...   \n84                                      2.397895   \n85                                      1.893788   \n86                                      1.159589   \n87                                      1.159589   \n88                                      1.414279   \n\n    T_z__permutation_entropy__dimension_6__tau_1  \\\n1                                      -0.000000   \n2                                       1.748067   \n3                                       2.163956   \n4                                       2.302585   \n5                                       2.302585   \n..                                           ...   \n84                                      2.302585   \n85                                      2.163956   \n86                                      1.227529   \n87                                      1.497866   \n88                                      1.609438   \n\n    T_z__permutation_entropy__dimension_7__tau_1  \\\n1                                      -0.000000   \n2                                       1.831020   \n3                                       2.197225   \n4                                       2.197225   \n5                                       2.197225   \n..                                           ...   \n84                                      2.197225   \n85                                      2.197225   \n86                                      1.303092   \n87                                      1.581094   \n88                                      1.831020   \n\n    T_z__query_similarity_count__query_None__threshold_0.0  \\\n1                                                 NaN        \n2                                                 NaN        \n3                                                 NaN        \n4                                                 NaN        \n5                                                 NaN        \n..                                                ...        \n84                                                NaN        \n85                                                NaN        \n86                                                NaN        \n87                                                NaN        \n88                                                NaN        \n\n    T_z__mean_n_absolute_max__number_of_maxima_7  \n1                                       0.000000  \n2                                       0.571429  \n3                                       0.571429  \n4                                       1.000000  \n5                                       0.857143  \n..                                           ...  \n84                                     24.285714  \n85                                      5.571429  \n86                                      9.285714  \n87                                     40.285714  \n88                                      5.428571  \n\n[88 rows x 4698 columns]\n","output_type":"stream"}],"execution_count":6},{"id":"e2914abd-4446-4870-9d13-fdb57d1a472f","cell_type":"code","source":"print(extracted_features.columns)","metadata":{"execution":{"iopub.status.busy":"2024-12-08T11:11:08.009305Z","iopub.execute_input":"2024-12-08T11:11:08.009711Z","iopub.status.idle":"2024-12-08T11:11:08.016368Z","shell.execute_reply.started":"2024-12-08T11:11:08.009646Z","shell.execute_reply":"2024-12-08T11:11:08.015174Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Index(['F_x__variance_larger_than_standard_deviation',\n       'F_x__has_duplicate_max', 'F_x__has_duplicate_min',\n       'F_x__has_duplicate', 'F_x__sum_values', 'F_x__abs_energy',\n       'F_x__mean_abs_change', 'F_x__mean_change',\n       'F_x__mean_second_derivative_central', 'F_x__median',\n       ...\n       'T_z__fourier_entropy__bins_5', 'T_z__fourier_entropy__bins_10',\n       'T_z__fourier_entropy__bins_100',\n       'T_z__permutation_entropy__dimension_3__tau_1',\n       'T_z__permutation_entropy__dimension_4__tau_1',\n       'T_z__permutation_entropy__dimension_5__tau_1',\n       'T_z__permutation_entropy__dimension_6__tau_1',\n       'T_z__permutation_entropy__dimension_7__tau_1',\n       'T_z__query_similarity_count__query_None__threshold_0.0',\n       'T_z__mean_n_absolute_max__number_of_maxima_7'],\n      dtype='object', length=4698)\n","output_type":"stream"}],"execution_count":7},{"id":"8edb0bbe-98a3-4245-b928-a4ce292889f3","cell_type":"markdown","source":"Нами получено 4764 столбца значений. Это количество признаков гораздо\tбольше того, которое можно вычислить вручную, но при работе с реальными наборами данных на их вычисление уйдет заметно больше времени. Решившись на развертывание настолько большого набора признаков, постарайтесь реалистично оценить как вычислительную мощность рабочего оборудования, так собственные способности и скорость анализа полученных результатов. Помните, что выбросы данных во временных рядах могут оказаться особенно сложнымии неудобными для последующего анализа. Обязательно убедитесь, что избранные вами признаки лишены их.","metadata":{}}]}